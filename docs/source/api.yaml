swagger: '2.0'
info:
  version: 2.9.0
  title: Koverse REST API
  description: |
    Specification for interacting with the Koverse Rest API
host: demo.koverse.com
consumes:
  - application/json
produces:
  - application/json
tags:
  - name: Authentication
    description: |
      Methods for logging in individual users.

      These methods only apply when using Koverse's built-in user management.
  - name: Data Sets
    description: |
      Create, configure, and delete Data Sets.
  - name: Data Set Attributes
    description: |
      List, inspect, and configure masking for data set attributes
  - name: Data Set Permissions
    description: >
      Control access to data in Data Sets.


      Access is controlled on a Group basis and includes actions such as writing
      to a Data Set, querying, deleting, changing configuration, etc.


      Note that these permissions are distinct from system permission which
      control things like which Groups can do things like create Data Sets,
      setup Transforms etc.
  - name: System Permissions
    description: |
      Control access to system functionality.
  - name: Indexing Policies
    description: >
      Control how Koverse indexes data in a data set.


      This includes specifying which attributes to index, how data should be
      tokenized, and which combinations of attributes should be combined into
      Composite Indexes.

      The set of available indexes affects which kinds of interactive queries
      Koverse can support.
  - name: Query
    description: >
      Interactively query Data Sets.


      Queries are designed to retrieve a specific subset of records, in many
      cases in less than a second.

      Applications can call query methods in response to user requests.
  - name: Records
    description: |
      Write and retrieve individual records and sets of sample records.
  - name: Source Types
    description: >
      List available Source types.

      Source types specify which parameters are available for each type of
      Source.
  - name: Sources
    description: |
      Sources are external data systems from which Koverse can ingest data.
  - name: Import Flows
    description: |
      Configure a Source to import external data to a specific Data Set.
  - name: Normalizations
    description: |
      Normalizations allow data to be modified as it is imported.
  - name: Import Jobs
    description: >
      Import jobs are used for importing data from an external Source into a
      Data Set.


      These jobs are executed by the Hadoop MapReduce or Spark frameworks
      asynchronously.

      Note that Koverse submits jobs to YARN which then executes them according
      to the way the YARN cluster is configured, which is typically a single
      queue so jobs are started on a first come, first serve basis.

      Jobs may run simultaneously as cluster resources allow.


      Jobs can be started or shutdown via these methods.
  - name: Import Schedules
    description: >
      Manage schedules for Import Flows.


      Schedules control how Import Jobs are started automatically.

      Import Jobs can still be created for Import Flows without schedules on an
      on-demand basis.
  - name: Transform Types
    description: >
      Get a list of transforms available in the system.

      Transform types specify which parameters are available for each type of
      Transform.
  - name: Transforms
    description: >
      Setup a partiular Transform Type to transform one or more data sets into a
      new Data Set.
  - name: Transform Jobs
    description: >
      Transform jobs process new data or all data in input Data Sets and write
      out results to an output Data Set.


      These jobs are executed by the Hadoop MapReduce or Spark frameworks
      asynchronously.

      Note that Koverse submits jobs to YARN which then executes them according
      to the way the YARN cluster is configured, which is typically a single
      queue so jobs are started on a first come, first serve basis.

      Jobs may run simultaneously as cluster resources allow.


      Jobs can be started or shutdown via these methods.
  - name: Transform Schedules
    description: >
      Manage schedules for Transforms.


      Schedules control how Transform Jobs are started automatically.

      Transforms Jobs can still be created for Transforms without schedules on
      an on-demand basis, or automatically as new data is ingested via Import
      Jobs into input Data Sets.
  - name: Sink Types
    description: |
      List and get available Sink types.
      Sinks are external systems to which Koverse can export data.
  - name: Sinks
    description: |
      Create, update, and delete Sinks.
      Sinks are external systems to which Koverse can export data.
  - name: Export Jobs
    description: >
      Export jobs write new data or all data in input Data Sets to an external
      Sink.


      These jobs are executed by the Hadoop MapReduce or Spark frameworks
      asynchronously.

      Note that Koverse submits jobs to YARN which then executes them according
      to the way the YARN cluster is configured, which is typically a single
      queue so jobs are started on a first come, first serve basis.

      Jobs may run simultaneously as cluster resources allow.


      Jobs can be started or shutdown via these methods.
  - name: Sink Schedules
    description: >
      Manage schedules for exporting to Sinks


      Schedules control how Export Jobs are started automatically.

      Export Jobs can still be created for Sinks without schedules on an
      on-demand basis or automatically as new data appears in input Data Sets.
  - name: Jobs
    description: >
      Start, monitor, and cancel data processing jobs.


      Data processing jobs are used for importing, transforming, and exporting
      data.

      These jobs are executed by the Hadoop MapReduce or Spark frameworks
      asynchronously.

      Koverse monitors the status of jobs, gathering information on the success
      or failure of a job, including gathering any error information about
      failed jobs.


      Jobs can be started or shutdown via these methods.

      Note that Koverse submits jobs to YARN which then executes them according
      to the way the YARN cluster is configured, which is typically a single
      queue so jobs are started on a first come, first serve basis.

      Jobs may run simultaneously as cluster resources allow.


      If two or more jobs will write on the same data set, one job may become
      blocked to allow the other job to complete its processing without
      inteference.

      In some cases a blocked job can be unblocked so it can proceed.
definitions:
  apiClient:
    type: object
    required:
      - clientName
    properties:
      id:
        type: string
      clientName:
        type: string
      clientSecret:
        type: string
      singleUser:
        type: boolean
      websiteUrl:
        type: string
      redirectUrl:
        type: string
      apiToken:
        type: string
      enabled:
        type: boolean
  dataSet:
    type: object
    required:
      - name
    properties:
      id:
        type: string
      name:
        type: string
        minLength: 4
        pattern: '^[a-zA-Z0-9- ]+$'
        example: Movies
      description:
        type: string
        example: List of Movies
      importFlowIds:
        type: array
        items:
          type: integer
        example:
          - 338
      createdTimestamp:
        type: integer
      updatedTimestamp:
        type: integer
  dataSetAttributes:
    type: object
    required:
      - name
    properties:
      id:
        type: string
        example: actor_1_name
      dataSetId:
        type: string
        example: movies_20171107_172745_048
      name:
        type: string
        example: actor_1_name
      presenceCount:
        type: integer
        example: 4155
      uniqueValueCount:
        type: integer
        example: 3982
      valueCount:
        type: integer
        example: 4155
      visualizationType:
        $ref: '#/definitions/visualizationType'
      types:
        type: array
        items:
          type: object
          properties:
            name:
              type: string
            displayName:
              type: string
            prevalence:
              type: number
      values:
        type: array
        items:
          type: object
          properties:
            occurrences:
              type: integer
            value:
              type: string
            coordinates:
              type: object
              properties:
                lat:
                  type: number
                long:
                  type: number
            countryId:
              type: string
            opacity:
              type: integer
      indexed:
        type: boolean
      masked:
        type: boolean
      maskers:
        type: array
        items:
          type: object
  dataSetAttributeUpdateList:
    type: object
    required:
      - attrs
    properties:
      attrs:
        type: array
        items:
          type: object
          properties:
            id:
              type: string
            indexed:
              type: boolean
            maskers:
              type: array
              items:
                type: object
                properties:
                  descriptionId:
                    type: string
                  exceptedGroupIds:
                    type: array
                    items:
                      type: integer
                  parameters:
                    type: object
                    properties:
                      setting:
                        type: string
  dataSetIndexingPolicy:
    type: object
    required:
      - id
      - dataSetId
      - fieldsInclusive
      - fields
      - compositeIndexes
      - createValueOnlyIndices
    properties:
      id:
        type: integer
        format: int64
        example: 1
      dataSetId:
        type: string
        example: movies_20171107_172745_048
      fieldsInclusive:
        type: boolean
        description: >-
          If true, specifies the fields to include. If false, specifies the
          fields to exclude
        example: true
      fields:
        type: array
        items:
          type: string
        description: The field names to either include or exclude
        example:
          - actor_1_name
      compositeIndexes:
        type: array
        items:
          type: array
          items:
            $ref: '#/definitions/fieldTypePair'
      createValueOnlyIndices:
        type: boolean
        example: true
  dataSetJob:
    type: object
    required:
      - id
      - dataSetId
    properties:
      id:
        type: string
      dataSetId:
        type: string
      createdAt:
        type: integer
      startedAt:
        type: integer
      endedAt:
        type: integer
      error:
        type: string
      origin:
        type: string
      progress:
        type: number
      type:
        type: string
    example:
      id: 720
      userId: 4
      creationDate: 1537394536892
      startedDate: 1537394546221
      endedDate: 1537394584108
      status: success
      errorDetail: null
      statusMessage: null
      userAcknowledged: false
      origin: UNSPECIFIED
      overrideBlockedStatus: false
      progress: 1
      type: REINDEXING
      dataSetId: movie_metadata_clean_20180817_180504_927
      errors: []
      outputDataSetId: null
      inputDataSetIds: null
      recordCount: 0
  dataSetMetadata:
    type: object
    description: |
      This object contains all the metadata associated with a data set.
    required:
      - name
    properties:
      id:
        type: string
      name:
        type: string
        minLength: 4
        pattern: '^[a-zA-Z0-9- ]+$'
      description:
        type: string
        description: A user-readable description of the data set.
      deleted:
        type: boolean
      groupPermissionsIds:
        type: array
      indexingPolicyId:
        type: integer
      indexingPolicy:
        type: string
      tags:
        type: string
      userId:
        type: integer
      useId:
        type: integer
        description: The user ID of the creator of this data set.
      createdTimestamp:
        type: integer
        description: Timestamp of when the data set was created.
      updatedTimestamp:
        type: integer
        description: Timestamp of the last time records were added.
      recordCountLastUpdate:
        type: integer
        description: Timestamp of the last time records were added.
      recordCount:
        type: integer
      sizeBytes:
        type: integer
      disableFieldStats:
        type: boolean
      disableSampling:
        type: boolean
      status:
        type: string
      hadoopDeleteJobIds:
        type: array
      dataStoreAuthRemoved:
        type: boolean
      version:
        type: integer
      importFlowId:
        type: string
      importFlowIds:
        type: array
        items:
          type: integer
        description: A list of IDs of import flows writing data to this data set.
      ageOffEnabled:
        type: boolean
      ageOffIndexDays:
        type: integer
      fieldStatsMinimumExecutionPeriod:
        type: integer
      samplingMinimumExecutionPeriod:
        type: integer
      aggregationMinimumExecutionPeriod:
        type: integer
      schemaMinimumExecutionPeriod:
        type: integer
      indexMinimumExecutionPeriod:
        type: integer
    example:
      id: movies_20171107_172745_048
      name: Movies
      description: List of Movies
      userId: 4
      createdTimestamp: 1510093665050
      updatedTimestamp: 1510093711178
      recordCountLastUpdated: 1510106324522
      recordCount: 4159
      importFlowIds:
        - 338
  dataSetPermission:
    type: object
    required:
      - groupId
      - dataSetId
    properties:
      id:
        type: string
      groupId:
        type: string
      dataSetId:
        type: string
      all:
        type: boolean
      read:
        type: boolean
      download:
        type: boolean
      write:
        type: boolean
      delete:
        type: boolean
      managePermissions:
        type: boolean
      manageConfiguration:
        type: boolean
      audit:
        type: boolean
      permissionsTypes:
        type: array
    example:
      id: 844
      dataSetId: movies_20171107_172745_048
      groupId: 1
      all: false
      read: false
      download: false
      write: false
      delete: false
      managePermissions: false
      manageConfiguration: false
      audit: false
      authorizerTypeId: null
      authorizerGroupId: null
      permissionsTypes: []
  dataSetResult:
    type: object
    description: >
      This object contains all the records matching a query against a single
      data set.
    properties:
      id:
        type: string
      name:
        type: string
      attributeMatchCount:
        type: integer
        format: int64
        description: Not used
      recordMatchCount:
        type: integer
        format: int64
        description: >
          The total number of records matching this query. It's possible for
          there to be more results than can be retreived in one call. In this
          case, more results can be fetched with subsequent calls that use the
          recordOffset parameter to get subsequent pages of results.
      recordCount:
        type: integer
        format: int64
        description: |
          The total number of records in this data set.
      createdTimestamp:
        type: integer
        format: int64
      updatedTimestamp:
        type: integer
        format: int64
      flatSchema:
        type: boolean
        description: >
          Whether records in this result set contain no nested values like
          arrays or maps
      recordMatchCountLimited:
        type: boolean
        description: >
          The backend only counts record matches up to 5000. If there are more
          results than this recordMatchCountLimited is true.
      records:
        type: array
        items:
          $ref: '#/definitions/record'
      successful:
        type: boolean
      errorMessage:
        type: string
    example:
      id: movies_20171107_172745_048
      name: movies
      attributeMatchCount: 0
      recordMatchCount: 20
      recordCount: 4159
      createdTimestamp: 1510093665050
      updatedTimestamp: 0
      flatSchema: true
      recordMatchCountLimited: false
      records:
        - $ref: '#/definitions/record/example'
      successful: true
      errorMessage: ''
  dataSetSchemas:
    type: object
    description: |
      Array of metadata of the schema of a dataset.
    required:
      - type
      - fieldTypeCounts
    properties:
      type:
        type: string
        example: SCALAR
      fieldTypeCounts:
        type: array
      fieldValueType:
        type: string
        example: DATE
  exportSchedule:
    type: object
    properties:
      sinkId:
        type: integer
        format: int64
      sinkDisplayName:
        type: string
  fieldTypePair:
    type: object
    required:
      - fieldName
      - fieldType
    properties:
      fieldName:
        type: string
      fieldType:
        type: boolean
  importFlow:
    type: object
    required:
      - sourceInstanceId
    properties:
      id:
        type: integer
        format: int64
      sourceInstanceId:
        type: integer
        format: int64
      dataSetId:
        type: string
      disabled:
        type: boolean
      type:
        type: string
        enum:
          - manual
          - continuous
          - periodic
      updatedAt:
        type: string
        format: dateTime
      executedAt:
        type: string
        format: dateTime
      executionCount:
        type: integer
      normalizations:
        type: array
        items:
          type: object
          properties:
            config:
              type: object
            typeId:
              type: string
      configurationOptions:
        type: object
    example:
      id: 50596
      responsibleUserId: 1
      disabled: false
      type: manual
      creationDate: 1534541944533
      lastUpdatedDate: 1534541944533
      lastExecutionDate: 1534529105371
      disabledDate: null
      executionCount: 1
      normalizations: []
      schedules: []
      configurationOptions: {}
      ingestState: {}
      sourceInstanceId: 50594
      outputDataSetId: movies_20171107_172745_048
  importSchedule:
    type: object
    required:
      - importFlowId
      - repeatUnit
      - repeatInterval
      - endingType
    properties:
      id:
        type: integer
        format: int64
      importFlowId:
        type: integer
        format: int64
      repeatInterval:
        type: integer
        format: int32
      repeatUnit:
        type: string
        enum:
          - Hourly
          - Daily
          - Weekly
          - Monthly
      endingType:
        type: string
        enum:
          - Never
          - Date
          - Count
      startDateTime:
        type: string
        format: dateTime
      endDateTime:
        type: string
        format: dateTime
      endAfter:
        type: integer
        format: int64
  job:
    type: object
    required:
      - id
      - dataSetId
    properties:
      id:
        type: string
        example: 67760
      userId:
        type: integer
        example: 1
      dataSetId:
        type: string
        example: movies_20171107_172745_048
      status:
        type: string
        example: running
      creationDate:
        type: integer
        example: 1539982556061
      startedDate:
        type: integer
        example: 1539982559008
      endedAt:
        type: integer
        example: 0
      error:
        type: string
      origin:
        type: string
        example: USER_REQUEST
      progress:
        type: number
      type:
        type: string
  login:
    type: object
    description: |
      This object contains the parameters necessary to authenticate.
    required:
      - email
      - password
    properties:
      email:
        type: string
      password:
        type: string
    example:
      email: zerocool@example.com
      password: supersecret
  logout:
    type: boolean
    example: true
    description: |
      This indicates whether the logout was successful.
  normalization:
    type: object
    required:
      - importFlowId
      - typeId
      - position
      - enabled
    properties:
      id:
        type: integer
      importFlowId:
        type: integer
      typeId:
        type: string
      position:
        type: integer
      enabled:
        type: boolean
      config:
        type: object
  normalizationType:
    type: object
    required:
      - displayName
      - typeId
    properties:
      typeId:
        type: string
      displayName:
        type: string
      description:
        type: string
      implementationClassName:
        type: string
      parameters:
        type: array
  parameter:
    type: object
    required:
      - displayName
      - parameterName
      - type
      - required
    properties:
      id:
        type: integer
        format: int64
      displayName:
        type: string
      parameterName:
        type: string
      type:
        type: string
        enum:
          - string
          - text
          - boolean
          - integer
          - enum
          - file
          - inputCollection
          - outputCollection
          - securityLabelParser
          - collectionField
          - collectionMultipleField
          - exportSingleOutput
      enumerations:
        type: array
        items:
          type: string
      defaultValue:
        type: string
      required:
        type: boolean
      hint:
        type: string
      javascriptClassName:
        type: string
      addOnId:
        type: integer
        format: int64
      parameterGroup:
        type: string
  record:
    type: object
    properties:
      recordId:
        type: string
      collectionId:
        type: string
      securityLabel:
        type: string
      value:
        type: object
        description: >
          An object containing the fields and values within this record. The
          structure of this object will vary from data set to data set. Here we
          include 'fieldOne', 'fieldTwo', etc. just as an example.
    example:
      recordId: null
      collectionId: movies_20171107_172745_048
      securityLabel: ''
      value:
        plot_keywords: african american|code|dog|pigeon|samurai
        country: France
        aspect_ratio: 1.85
        actor_3_facebook_likes: 116
        num_critic_for_reviews: 167
        color: Color
        language: English
        title_year: 1999
        imdb_score: 7.5
        duration: 116
        genres: Action|Crime|Drama|Thriller
        actor_1_name: Henry Silva
        director_facebook_likes: 0
        content_rating: R
        num_voted_users: 70084
        gross: 3300230
        facenumber_in_poster: 1
        actor_2_name: Gano Grills
        num_user_for_reviews: 346
        actor_1_facebook_likes: 251
        movie_title: Ghost Dog - The Way of the Samurai
        movie_facebook_likes: 0
        actor_2_facebook_likes: 147
        movie_imdb_link: 'http://www.imdb.com/title/tt0165798/?ref_=fn_tt_tt_1'
        director_name: Jim Jarmusch
        cast_total_facebook_likes: 675
        actor_3_name: Richard Portnow
      matchValues: null
      isMatch: false
  sink:
    type: object
    properties:
      id:
        type: integer
        format: int64
      name:
        type: string
      configurationOptions:
        type: object
      disabled:
        type: boolean
      sinkTypeId:
        type: string
      scheduleType:
        type: string
      responsibleUser:
        $ref: '#/definitions/user'
      transforms:
        type: array
        items:
          $ref: '#/definitions/sinkTransformConfiguration'
      inputDataWindowType:
        type: string
      dataSetId:
        type: string
  sinkType:
    type: object
    required:
      - name
    properties:
      typeId:
        type: string
      name:
        type: string
      parameters:
        type: array
  sinkTypeDescription:
    type: object
    required:
      - name
      - implementationClassName
      - sinkTypeId
      - sinkParameters
      - disabled
      - version
    properties:
      id:
        type: integer
        format: int64
      name:
        type: string
      implementationClassName:
        type: string
      sinkTypeId:
        type: string
      sinkParameters:
        type: array
        items:
          $ref: '#/definitions/parameter'
      disabled:
        type: boolean
      version:
        type: string
  sinkTransformConfiguration:
    type: object
    properties:
      typeId:
        type: string
      implementationClassName:
        type: string
      config:
        type: object
  source:
    type: object
    required:
      - name
    properties:
      id:
        type: integer
        format: int64
      name:
        type: string
      importFlowId:
        type: string
      sourceTypeId:
        type: string
      configurationOptions:
        type: object
      disabled:
        type: boolean
      isSchedulable:
        type: boolean
      clearOutputDataSet:
        type: boolean
  sourceInstance:
    type: object
    required:
      - name
    properties:
      id:
        type: integer
        format: int64
      name:
        type: string
      importFlowId:
        type: string
      sourceTypeId:
        type: string
      configurationOptions:
        type: object
      disabled:
        type: boolean
      isSchedulable:
        type: boolean
      clearOutputDataSet:
        type: boolean
  sourceTypeDescription:
    type: object
    required:
      - name
    properties:
      id:
        type: string
      name:
        type: string
      version:
        type: string
      implementationClassName:
        type: string
      sourceTypeId:
        type: string
      customParameterFromJavascriptPath:
        type: string
      parameters:
        type: array
      flowParameters:
        type: array
      disabled:
        type: boolean
      executionMethod:
        type: string
      addonId:
        type: string
  success:
    type: object
    required:
      - success
    properties:
      success:
        type: boolean
      successMessage:
        type: string
  transform:
    type: object
    required:
      - transformTypeId
      - configurationOptions
    properties:
      id:
        type: string
      displayName:
        type: string
      configurationOptions:
        type: object
      transformTypeId:
        type: string
      scheduleType:
        type: string
      inputDataSetIds:
        type: array
      outputDataSetId:
        type: string
      replaceOutputData:
        type: boolean
      inputDataWindowType:
        type: string
  transformSchedule:
    type: object
    required:
      - transformId
      - repeatUnit
      - repeatInterval
      - endingType
    properties:
      id:
        type: integer
        format: int64
      transformId:
        type: integer
        format: int64
      repeatInterval:
        type: integer
        format: int32
      repeatUnit:
        type: string
        enum:
          - Hourly
          - Daily
          - Weekly
          - Monthly
      endingType:
        type: string
        enum:
          - Never
          - Date
          - Count
      startDateTime:
        type: string
        format: dateTime
      endDateTime:
        type: string
        format: dateTime
      endAfter:
        type: integer
        format: int64
  transformType:
    type: object
    required:
      - name
    properties:
      typeId:
        type: string
      name:
        type: string
      parameters:
        type: array
  searchAutocomplete:
    type: object
    required:
      - type
      - value
    properties:
      type:
        type: string
      value:
        type: string
      dataSetId:
        type: string
      labelId:
        type: string
  user:
    type: object
    required:
      - firstName
      - lastName
      - email
    properties:
      id:
        type: integer
        format: int64
      firstName:
        type: string
      lastName:
        type: string
      email:
        type: string
        description: username or email used to login
    example:
      id: 1
      firstName: Dade
      lastName: Murphy
      email: zerocool@example.com
  visualizationType:
    type: string
    enum:
      - line
      - bar
      - pie
      - chloropleth-countries
      - heatmap
      - list
      - single-value
parameters:
  applicationId:
    name: applicationId
    in: path
    description: ID of the application
    required: true
    type: string
  dataSet:
    name: dataSet
    in: body
    description: Dataset attributes
    required: true
    schema:
      $ref: '#/definitions/dataSet'
  dataSetAttributeUpdateList:
    name: dataSetAttributeUpdateList
    in: body
    description: Attribute update list for masking attributes
    required: true
    schema:
      $ref: '#/definitions/dataSetAttributeUpdateList'
  dataSetId:
    name: dataSetId
    in: path
    description: ID of the data set
    required: true
    type: string
  dataSetMetadata:
    name: dataSetMetadata
    in: body
    description: Metadata of a dataset
    required: true
    schema:
      $ref: '#/definitions/dataSetMetadata'
  exportJobId:
    name: exportJobId
    in: path
    description: ID of the export job
    required: true
    type: string
  exportScheduleId:
    name: exportScheduleId
    in: path
    description: ID of an export schedule
    required: true
    type: string
  fileType:
    name: fileType
    in: path
    description: fileType to download
    required: true
    type: string
    enum:
      - json
      - csv
  importFlowId:
    name: importFlowId
    in: query
    description: ID of the import flow
    required: true
    type: string
  importFlowIdPath:
    name: importFlowId
    in: path
    description: ID of the import flow
    required: true
    type: string
  importJobId:
    name: importJobId
    in: path
    description: ID of the import job
    required: true
    type: integer
    format: int64
  importScheduleId:
    name: importScheduleId
    in: path
    description: ID of the import schedule
    required: true
    type: string
  jobId:
    name: jobId
    in: path
    description: ID of the job
    required: true
    type: string
  normalizationId:
    name: normalizationId
    in: path
    description: ID of the normalization
    required: true
    type: string
  objectQuery:
    name: query
    in: body
    required: true
    schema:
      type: object
      required:
        - query
      description: >
        This object contains the parameters used to issue a query against one or
        more data sets. The query is defined as a JSON string
      properties:
        collectionIds:
          type: array
          items:
            type: string
          description: >
            A list of data set IDs. Specifying an empty list will cause the
            query to be issued to all data sets the user is allowed to query.
        query:
          type: string
          description: >
            A query represented as a JSON string


            ### Examples


            Search for a value in any field


            `{$any: fmv}`


            Search for a value in a specific field


            `{field.name: fmv}`


            Combine criteria usin AND


            `{$and: [{$any: fmv}, {$any: blue}]}`


            Combine criteria using OR


            `{$or: [{$any: fmv}, {$any: blue}]}`


            ### Range Queries


            A value in any field greater than or equal to 160


            `{$any: {$gte:160}}`


            Date field less than a specific date


            `{date_created: {$lt: “1980-01-01T00:00:00.000Z}}`


            Geo Range


            `{fieldName: {$box: [[sw-lat, sw-long],[ne-lat, ne-long]]}}`


            E.g. `{fieldName: {$box :[[39.5, -104.9],[40, -104.5]]}}`


            Note that queries that combine a range with any other criteria, and

            queries that combine multiple ranges require Composite Indexes on

            the fields involved. See

            [additional
            docs](http://koverse.readthedocs.io/en/2.3/dev/dataset.html#compositeindexes)

            for information on building these.
        auths:
          type: array
          items:
            type: string
          description: >
            An optional comma separated list of authorization tokens. These are
            used for applying record-level filtering of data set results to
            records that have additional security labels applied.
        fieldsToReturn:
          type: array
          items:
            type: string
          description: >
            The list of field names to include in records. Other fields will be
            excluded. Omitting this parameter will cause all fields to be
            included in records.
        limit:
          type: integer
          description: The number of results to fetch in this call
        offset:
          type: integer
          description: The number of records in the result set to skip
      example:
        collectionIds:
          - movies_20171107_172745_048
        query:
          title: jurassic
        fieldsToReturn:
          - movie_title
          - title_year
          - gross
        limit: 100
  objectQueryNames:
    name: query
    in: body
    required: true
    schema:
      type: object
      required:
        - query
      description: >
        This object contains the parameters used to issue a query against one or
        more data sets. The query is defined as a JSON string
      properties:
        collectionNames:
          type: array
          items:
            type: string
          description: >
            A list of data set names. Specifying an empty list will cause the
            query to be issued to all data sets the user is allowed to query.
        query:
          type: string
          description: >
            A query represented as a JSON string


            ### Examples


            Search for a value in any field


            `{$any: fmv}`


            Search for a value in a specific field


            `{field.name: fmv}`


            Combine criteria usin AND


            `{$and: [{$any: fmv}, {$any: blue}]}`


            Combine criteria using OR


            `{$or: [{$any: fmv}, {$any: blue}]}`


            ### Range Queries


            A value in any field greater than or equal to 160


            `{$any: {$gte:160}}`


            Date field less than a specific date


            `{date_created: {$lt: “1980-01-01T00:00:00.000Z}}`


            Geo Range


            `{fieldName: {$box: [[sw-lat, sw-long],[ne-lat, ne-long]]}}`


            E.g. `{fieldName: {$box :[[39.5, -104.9],[40, -104.5]]}}`


            Note that queries that combine a range with any other criteria, and

            queries that combine multiple ranges require Composite Indexes on

            the fields involved. See

            [additional
            docs](http://koverse.readthedocs.io/en/2.3/dev/dataset.html#compositeindexes)

            for information on building these.
        auths:
          type: array
          items:
            type: string
          description: >
            An optional comma separated list of authorization tokens. These are
            used for applying record-level filtering of data set results to
            records that have additional security labels applied.
        fieldsToReturn:
          type: array
          items:
            type: string
          description: >
            The list of field names to include in records. Other fields will be
            excluded. Omitting this parameter will cause all fields to be
            included in records.
        limit:
          type: integer
          description: The number of results to fetch in this call
        offset:
          type: integer
          description: The number of records in the result set to skip
      example:
        collectionNames:
          - movies
        query:
          title: jurassic
        fieldsToReturn:
          - movie_title
          - title_year
          - gross
        limit: 100
  permissionId:
    name: permissionId
    in: path
    description: ID of the permission
    required: true
    type: string
  recordId:
    name: recordId
    in: query
    description: ID of the record
    required: true
    type: string
  recordStyle:
    name: recordStyle
    in: query
    description: |
      Requests a more efficient representation of records
    required: false
    type: string
    enum:
      - 2.2
  sink:
    name: sink
    in: body
    required: true
    schema:
      $ref: '#/definitions/sink'
  sinkId:
    name: sinkId
    in: path
    description: ID of the sink
    type: integer
    required: true
  sinkTypeId:
    name: sinkTypeId
    in: path
    description: ID of the sink type
    required: true
    type: integer
    format: int64
  sourceId:
    name: sourceId
    in: path
    description: ID of the source
    required: true
    type: string
  sourceInstanceId:
    name: sourceInstanceId
    in: path
    description: ID of the source
    required: true
    type: string
  transformId:
    name: transformId
    in: path
    description: ID of a transform
    type: integer
    required: true
    format: int64
  transformJobId:
    name: transformJobId
    in: path
    required: true
    description: ID of the transform job
    type: integer
    format: int64
  transformScheduleId:
    name: transformScheduleId
    in: path
    required: true
    description: ID of the transform schedule
    type: integer
    format: int64
paths:
  /api/login:
    post:
      summary: Login
      operationId: loginUser
      tags:
        - Authentication
      description: >
        Authenticate a user and create an authenticated web session. This must
        be

        called before calling other methods.
      parameters:
        - name: loginParams
          in: body
          description: login object
          required: true
          schema:
            $ref: '#/definitions/login'
      responses:
        '200':
          description: Returns the user data
          schema:
            $ref: '#/definitions/user'
  /api/logout:
    get:
      summary: Logout
      operationId: logoutUser
      tags:
        - Authentication
      description: >
        Closes the authenticated web session.

        Subsequent API calls will fail with code 401 Unauthorized until a new
        session is created via login.
      responses:
        '200':
          description: Returns a confirmation of the logout
          schema:
            $ref: '#/definitions/logout'
  /api/applications:
    get:
      summary: List
      operationId: findApplications
      tags:
        - Applications
      description: |
        Get a list of application objects for all applctations the user is
        authorized to see.
      responses:
        '200':
          description: Returns metadata for all applications the user is authorized to see
          schema:
            type: array
            items:
              $ref: '#/definitions/apiClient'
    post:
      summary: Create
      operationId: createApplication
      tags:
        - Applications
      description: |
        Creates a new application.
      parameters:
        - name: body
          in: body
          description: Application object to create
          required: true
          schema:
            $ref: '#/definitions/apiClient'
      responses:
        '201':
          description: Returns the newly created Application
          schema:
            $ref: '#/definitions/apiClient'
  '/api/applications/{applicationId}':
    parameters:
      - $ref: '#/parameters/applicationId'
    get:
      summary: Get
      description: |
        Get the details about the given application.
      operationId: findApplicationById
      tags:
        - Applications
      responses:
        '200':
          description: Returns the application details
          schema:
            $ref: '#/definitions/apiClient'
    put:
      summary: Update
      description: |
        Update the application details.
      operationId: updateApplicationById
      tags:
        - Applications
      responses:
        '200':
          description: Returns the updated application details.
          schema:
            $ref: '#/definitions/apiClient'
    delete:
      summary: Delete
      description: |
        Delete the application specified by id.
      operationId: deleteApplicationById
      tags:
        - Applications
      responses:
        '200':
          description: Returns the deleted application.
          schema:
            $ref: '#/definitions/apiClient'
  /api/dataSets:
    get:
      summary: List
      operationId: findDataSets
      tags:
        - Data Sets
      description: |
        Get a list of data set metadata objects for all data sets the user is
        authorized to see.
      responses:
        '200':
          description: Returns metadata for all data sets the user is authorized to see
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetMetadata'
    post:
      summary: Create
      operationId: createDataSet
      tags:
        - Data Sets
      description: >
        Creates a new empty data set.


        Note: This call will fail if there is already a data set with the same
        name as the requested new data set.
      parameters:
        - name: body
          in: body
          description: Data Set object to create
          required: true
          schema:
            $ref: '#/definitions/dataSet'
      responses:
        '201':
          description: Returns the newly created Data Set metadata
          schema:
            $ref: '#/definitions/dataSetMetadata'
  '/api/dataSets/{dataSetId}':
    parameters:
      - $ref: '#/parameters/dataSetId'
    get:
      summary: Get
      description: |
        Get the name, description, record count, and other information
        about the given data set. Does not return any records within the
        data set.
      operationId: findDataSetById
      tags:
        - Data Sets
      responses:
        '200':
          description: Returns the data set metadata
          schema:
            $ref: '#/definitions/dataSetMetadata'
    put:
      summary: Update
      description: |
        Update the data set metadata.
      operationId: updateDataSetById
      tags:
        - Data Sets
      responses:
        '200':
          description: Returns the updated data set metadata.
          schema:
            $ref: '#/definitions/dataSetMetadata'
    delete:
      summary: Delete
      description: |
        Delete the data set specified by dataSetId.
      operationId: deleteDataSetById
      tags:
        - Data Sets
      responses:
        '200':
          description: Returns the data set metadata with an updated DELETED dataset name.
          schema:
            $ref: '#/definitions/dataSetMetadata'
  '/api/dataSets/{dataSetId}/attributeNames':
    parameters:
      - $ref: '#/parameters/dataSetId'
    get:
      summary: List names
      operationId: findDataSetAttributeNames
      tags:
        - Data Set Attributes
      description: >
        Get a list of the names of fields or attributes within a data set.

        These can be used to inform users of what fields are available so

        they can be used in queries.


        This method fetches the names of attributes only, and doesn't return any
        statistics or metadata collected about attributes.
      responses:
        '200':
          description: Returns all data set attribute names
          schema:
            type: array
            items:
              type: string
  '/api/dataSets/{dataSetId}/attributes':
    parameters:
      - $ref: '#/parameters/dataSetId'
    get:
      summary: Get metadata
      operationId: findDataSetAttributes
      tags:
        - Data Set Attributes
      description: >
        Get the metadata of all attributes of a data set.


        Metadata includes statistical information about the values found in each
        attribute.
      responses:
        '200':
          description: Returns an array of metadata of each attribute of a data set.
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetAttributes'
  '/api/dataSets/{dataSetId}/clearDataSet':
    parameters:
      - $ref: '#/parameters/dataSetId'
    get:
      summary: Clear
      operationId: clearDataSetById
      tags:
        - Data Sets
      description: >-
        Clears a data set of all data.

        This involves dropping data stored in Accumulo using the deleterows
        command and should be called sparingly.
      responses:
        '200':
          description: 200 OK
  '/api/dataSets/{dataSetId}/indexingPolicy':
    parameters:
      - $ref: '#/parameters/dataSetId'
    get:
      summary: Get
      operationId: findDataSetIndexingPolicyById
      tags:
        - Indexing Policies
      description: >
        Get data set indexing policy metadata including indexed fields,
        composite indexes and foreign language indexing by data set id.
      responses:
        '200':
          description: Returns an array of the indexing policy metadata of a data set.
          schema:
            $ref: '#/definitions/dataSetIndexingPolicy'
    put:
      summary: Update
      operationId: updateDataSetIndexingPolicyById
      tags:
        - Indexing Policies
      parameters:
        - name: dataSetIndexingPolicy
          in: body
          description: The updated data set indexing policy
          required: true
          schema:
            $ref: '#/definitions/dataSetIndexingPolicy'
      description: >
        Updates the indexing policy for a data set by data set id.


        Changing the indexing policy will trigger an asynchronous reindexing job
        that will apply the changes.
      responses:
        '200':
          description: Returns an array of the indexing policy metadata of a data set.
          schema:
            $ref: '#/definitions/dataSetIndexingPolicy'
  '/api/dataSets/{dataSetId}/permissions':
    parameters:
      - $ref: '#/parameters/dataSetId'
    get:
      summary: Get
      operationId: findDataSetPermissions
      tags:
        - Data Set Permissions
      description: |
        Get permissions granted for a data set by data set id.
      responses:
        '200':
          description: Returns an array of metadata of the permissions of a data set.
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetPermission'
    post:
      summary: Create
      operationId: createDataSetPermission
      tags:
        - Data Set Permissions
      parameters:
        - name: dataSetPermission
          in: body
          description: The data set permission to add
          required: true
          schema:
            $ref: '#/definitions/dataSetPermission'
      description: |
        Assigns group permissions to the specified data set.
      responses:
        '201':
          description: Returns an array of metadata of the permissions of a data set.
          schema:
            $ref: '#/definitions/dataSetPermission'
  '/api/dataSets/{dataSetId}/permissions/{permissionId}':
    parameters:
      - $ref: '#/parameters/dataSetId'
      - $ref: '#/parameters/permissionId'
    put:
      summary: Update
      operationId: updateDataSetPermissionsById
      tags:
        - Data Set Permissions
      parameters:
        - name: dataSetPermission
          in: body
          description: The updated data set permission info
          required: true
          schema:
            $ref: '#/definitions/dataSetPermission'
      description: |
        Updates the permissions of a data set specified by a data set ID.
      responses:
        '200':
          description: Returns the updated data set permission data
          schema:
            $ref: '#/definitions/dataSetPermission'
    delete:
      summary: Delete
      operationId: deleteDataSetPermissionsById
      tags:
        - Data Set Permissions
      description: |
        Deletes a data set permission based on the supplied permission id.

        This effectively revokes access.
      responses:
        '200':
          description: Returns the data set permission that was deleted
          schema:
            $ref: '#/definitions/dataSetPermission'
  '/api/dataSets/{dataSetId}/jobs':
    parameters:
      - $ref: '#/parameters/dataSetId'
    get:
      summary: Get for a data set
      operationId: getJobsMetadata
      tags:
        - Jobs
      description: |
        Get the metadata of the jobs run on a data set by data set id.
      responses:
        '200':
          description: Returns an array of metadata for all jobs run on a data set.
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetJob'
  '/api/dataSets/{dataSetId}/records':
    parameters:
      - $ref: '#/parameters/dataSetId'
      - $ref: '#/parameters/recordStyle'
    get:
      summary: Get sample records
      operationId: findDataSetRecordsById
      tags:
        - Data Sets
        - Records
      description: >
        Returns all the fields and values for a sample of records by data set
        id.


        Note: The recordStyle query parameter defaults to a value of "2.1".

        To return json output of records, you must specify the recordStyle query
        parameter "2.2".
      responses:
        '200':
          description: Return a sample of records for a data set.
          schema:
            type: object
            properties:
              flatSchema:
                type: boolean
              records:
                type: array
                items:
                  $ref: '#/definitions/record'
  '/api/dataSets/{dataSetId}/repair':
    parameters:
      - $ref: '#/parameters/dataSetId'
    get:
      summary: Repair
      operationId: repairDataSetById
      tags:
        - Data Sets
      description: >
        Repairs a data set by dataSetId.


        This will delete a data set's index entries, attribute statistics,
        record samples, and schema information and start an asynchronous job to
        regenerate that information from data set records.
      responses:
        '200':
          description: 200 OK
  '/api/dataSets/{dataSetId}/attributes/masking':
    parameters:
      - $ref: '#/parameters/dataSetId'
    put:
      summary: Update masking
      operationId: updateDataSetAttributesMaskingByID
      tags:
        - Data Set Attributes
      description: |
        Updates the masked attributes of a data set.
      parameters:
        - name: attrs
          in: body
          description: Attribute objects
          required: true
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetAttributes'
      responses:
        '200':
          description: >-
            Returns the updated list of data set attributes for the specified
            data set.
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetAttributes'
  /api/importFlows:
    post:
      summary: Create
      operationId: addImportFlow
      tags:
        - Import Flows
      description: >
        Create a new Import Flow, associating a Source with a Data Set.


        Once this is created, an Import Job can be started to ingest data from
        the external Source into the Data Set.
      parameters:
        - name: importFlow
          in: body
          description: The importFlow to add
          required: true
          schema:
            $ref: '#/definitions/importFlow'
      responses:
        '201':
          description: Returns the newly created import flow
          schema:
            $ref: '#/definitions/importFlow'
  '/api/importFlows/{importFlowId}':
    parameters:
      - $ref: '#/parameters/importFlowIdPath'
    get:
      summary: Get
      operationId: findImportFlowById
      tags:
        - Import Flows
      description: Gets an import flow by id.
      responses:
        '200':
          description: Returns the import flow data
          schema:
            $ref: '#/definitions/importFlow'
    delete:
      summary: Delete
      operationId: deleteImportFlowById
      tags:
        - Import Flows
      description: Deletes the specified import flow if it exists.
      responses:
        '200':
          description: Returns the deleted import flow data
          schema:
            $ref: '#/definitions/importFlow'
    put:
      summary: Update
      operationId: updateImportFlowById
      tags:
        - Import Flows
      description: Updates the import flow.
      parameters:
        - name: importFlow
          in: body
          description: The updated import flow info
          required: true
          schema:
            $ref: '#/definitions/importFlow'
      responses:
        '200':
          description: Returns the updated import flow data
          schema:
            $ref: '#/definitions/importFlow'
  '/api/importFlows/{importFlowId}/execute':
    parameters:
      - $ref: '#/parameters/importFlowIdPath'
    post:
      summary: Start
      operationId: funImportFlowById
      tags:
        - Import Jobs
      description: >
        Starts a new job to import data from the associated Source into the
        specified Data Set.
      responses:
        '200':
          description: Returns the success or failure of starting the job.
          schema:
            type: object
            properties:
              success:
                type: boolean
        '400':
          description: Returns the success or failure of running the import flow
          schema:
            type: object
            properties:
              failureMessage:
                type: string
  '/api/importFlows/{importFlowId}/normalizations':
    parameters:
      - $ref: '#/parameters/importFlowIdPath'
    get:
      summary: Get for an import flow
      tags:
        - Normalizations
      operationId: findNormalizations
      description: |
        Get any Normalizations associated with the specified Import Flow.
      responses:
        '200':
          description: Returns the normalizations for an importFlow
          schema:
            type: array
            items:
              $ref: '#/definitions/normalization'
    post:
      summary: Create
      tags:
        - Normalizations
      operationId: addNormalization
      description: |
        Adds a Normalization to an Import Flow.
      parameters:
        - name: normalization
          in: body
          description: The normalization to add
          required: true
          schema:
            $ref: '#/definitions/normalization'
      responses:
        '201':
          description: Returns the newly-added normalization
          schema:
            $ref: '#/definitions/normalization'
  '/api/importFlows/{importFlowId}/normalizations/{normalizationId}':
    parameters:
      - $ref: '#/parameters/importFlowIdPath'
      - $ref: '#/parameters/normalizationId'
    get:
      summary: Get
      operationId: findNormalizationById
      tags:
        - Normalizations
      description: Get a Normalization
      responses:
        '200':
          description: Returns the normalization data
          schema:
            $ref: '#/definitions/normalization'
    put:
      summary: Update
      operationId: updateNormalizationById
      tags:
        - Normalizations
      description: Update a Normalization
      parameters:
        - name: normalization
          in: body
          description: The updated normalization info
          required: true
          schema:
            $ref: '#/definitions/normalization'
      responses:
        '200':
          description: Returns the updated normalization data
          schema:
            $ref: '#/definitions/normalization'
    delete:
      summary: Delete
      operationId: deleteNormalization
      tags:
        - Normalizations
      description: Delete a Normalization
      responses:
        '200':
          description: Returns the normalization that was deleted
          schema:
            $ref: '#/definitions/normalization'
  '/api/importFlows/{importFlowId}/schedules':
    parameters:
      - $ref: '#/parameters/importFlowIdPath'
    get:
      summary: Get by Import Flow
      operationId: findImportSchedules
      tags:
        - Import Schedules
      description: |
        Get all schedules associated with the given Import Flow.
      responses:
        '200':
          description: Returns the matching import schedules
          schema:
            type: array
            items:
              $ref: '#/definitions/importSchedule'
  '/api/importFlows/source/{sourceId}':
    parameters:
      - $ref: '#/parameters/sourceId'
    get:
      summary: Get by source
      operationId: findImportFlowBySourceId
      tags:
        - Import Flows
      description: |
        Get an Import Flow associated with the given Source ID.
      responses:
        '200':
          description: Returns the import flow data
          schema:
            $ref: '#/definitions/importFlow'
  '/api/importJobs/{importJobId}/shutdown':
    parameters:
      - $ref: '#/parameters/importJobId'
    get:
      summary: Shutdown
      operationId: shutdownImportJobById
      tags:
        - Import Jobs
      description: |
        Shutdown the specified Import Job.
      responses:
        '200':
          description: Returns an updated job
          schema:
            $ref: '#/definitions/dataSetJob'
  /api/importSchedules:
    parameters:
      - $ref: '#/parameters/importFlowId'
    post:
      summary: Create
      operationId: addImportSchedule
      tags:
        - Import Schedules
      description: |
        Create a new Import Schedule.
      parameters:
        - name: importSchedule
          in: body
          description: The import schedule to add
          required: true
          schema:
            $ref: '#/definitions/importSchedule'
      responses:
        '201':
          description: Returns the newly-added import schedule
          schema:
            $ref: '#/definitions/importSchedule'
  '/api/importSchedules/{importScheduleId}':
    parameters:
      - $ref: '#/parameters/importScheduleId'
    get:
      summary: Get
      operationId: findImportScheduleById
      tags:
        - Import Schedules
      description: |
        Get the specified Import Schedule.
      responses:
        '200':
          description: Returns the import schedule data
          schema:
            $ref: '#/definitions/importSchedule'
    delete:
      summary: Delete
      operationId: deleteImportSchedule
      tags:
        - Import Schedules
      description: |
        Delete the specified Import Schedule.
      responses:
        '200':
          description: Returns the import schedule that was deleted
          schema:
            $ref: '#/definitions/importSchedule'
  /api/jobs:
    get:
      summary: Get active
      operationId: findActiveJobs
      tags:
        - Jobs
      description: |
        Returns a list of all active jobs
      responses:
        '200':
          description: Returns the active jobs
          schema:
            type: array
            items:
              $ref: '#/definitions/job'
  '/api/jobs/{jobId}/shutdown':
    parameters:
      - $ref: '#/parameters/jobId'
    get:
      summary: Shutdown
      operationId: shutdownJobById
      tags:
        - Jobs
      description: |
        Shutdown the specified job.
      responses:
        '200':
          description: 200 OK
  '/api/jobs/{jobId}/unblock':
    parameters:
      - $ref: '#/parameters/jobId'
    get:
      summary: Unblock
      operationId: unblockJob
      tags:
        - Jobs
      description: >
        Unblock the specified blocked job.


        This will cause the job to be started as soon as cluster resources
        allow.
      responses:
        '200':
          description: 200 OK
  /api/normalizationTypes:
    get:
      summary: List types
      operationId: findNormalizationTypes
      tags:
        - Normalizations
      description: |
        List all available Normalization types.
      responses:
        '200':
          description: Returns the matching normalization types
          schema:
            type: array
            items:
              $ref: '#/definitions/normalizationType'
  /api/permissions/dataset:
    get:
      summary: List
      operationId: dataSetPermissions
      tags:
        - Data Set Permissions
      description: |
        List available data set permissions
      responses:
        '200':
          description: >
            Returns available data set permissions that can be applied, such as
            the permission to read, write, etc.
          schema:
            type: array
            items:
              type: string
  /api/permissions/system:
    get:
      summary: List
      operationId: systemPermissions
      tags:
        - System Permissions
      description: |
        List the available system permissions
      responses:
        '200':
          description: Returns the users system permissions metadata.
          schema:
            type: array
            items:
              type: string
  /api/records:
    parameters:
      - $ref: '#/parameters/recordId'
    get:
      summary: Get
      operationId: getRecordById
      tags:
        - Records
      parameters:
        - name: datasetId
          type: string
          in: query
          required: true
        - name: recordId
          type: string
          in: query
          required: true
      description: >
        Get a single record by data set id and record id.


        Note that the Record ID must be known in order to use this method.

        It is intended to be used by applications that need to fetch one record,
        often one that is related to some other record.


        For example, a Transform may be designed to extract interesting features
        from original records that may consist of larger documents.

        Users searching the features may want to fetch the original larger
        record associated with these features.
      responses:
        '200':
          description: Returns the single record data.
          schema:
            properties:
              flatSchema:
                type: boolean
              records:
                type: array
                items:
                  $ref: '#/definitions/record'
    post:
      summary: Create
      operationId: createRecord
      tags:
        - Records
      description: >
        Writes a single record to the specified data set.


        Note that this syncs the newly written record to Accumulo before
        returning and so is not suitable for writing many records one after
        another.

        It is intended primarily to allow some applications to write new records
        to a Data Set when a user needs to write one record.


        It is recommended to use a Source and Import Flow to ingest data into a
        Data Set when many records need to be written.


        Note that this method will write the record and it's index entries
        according to the Indexing Policy associated with the Data Set being
        written to.

        But the Data Set's stats, samples, and schema information are not
        automatically updated.

        To update this information, a repair job can be run on the Data Set.
      responses:
        '200':
          description: Returns the single record data.
          schema:
            type: object
            properties:
              flatSchema:
                type: boolean
              records:
                type: array
                items:
                  $ref: '#/definitions/record'
  /api/sinks:
    parameters:
      - name: dataSetId
        in: query
        description: ID of the data set
        required: true
        type: string
    get:
      summary: Get for data set
      operationId: findSinks
      tags:
        - Sinks
      description: |
        Get a list of Sinks associated with the given Data Set ID.
      responses:
        '200':
          description: Returns the matching sinks
          schema:
            type: array
            items:
              $ref: '#/definitions/sink'
    post:
      summary: Create
      operationId: createSink
      tags:
        - Sinks
      description: >
        Create a new Sink representing an external system to which data can be
        exported.


        After a Sink is created, Export Jobs can be started to write data to the
        system described by the Sink.
      parameters:
        - name: sink
          in: body
          description: The sink to add
          required: true
          schema:
            $ref: '#/definitions/sink'
      responses:
        '200':
          description: Returns the new sink data
          schema:
            type: array
            items:
              $ref: '#/definitions/sink'
  '/api/sinks/{sinkId}':
    parameters:
      - $ref: '#/parameters/sinkId'
    get:
      summary: Get
      operationId: findSinkById
      tags:
        - Sinks
      description: |
        Get a Sink by ID
      responses:
        '200':
          description: Returns the sink data
          schema:
            $ref: '#/definitions/sink'
    delete:
      summary: Delete
      operationId: deleteSinkById
      tags:
        - Sinks
      description: |
        Disables a single Sink based on the ID supplied.

        Sinks are not deleted for auditing purposes.
      responses:
        '200':
          description: Returns the sink that was disabled
          schema:
            $ref: '#/definitions/sink'
    put:
      summary: Update
      operationId: updateSinkById
      tags:
        - Sinks
      description: |
        Updates a Sink by ID
      parameters:
        - name: sink
          in: body
          description: The updated sink info
          required: true
          schema:
            $ref: '#/definitions/sink'
      responses:
        '200':
          description: Returns the updated sink data
          schema:
            $ref: '#/definitions/sink'
  '/api/sink/{sinkId}/runExport':
    parameters:
      - $ref: '#/parameters/sinkId'
    get:
      summary: Start
      operationId: exportBySinkId
      tags:
        - Export Jobs
      description: |
        Start an Export Job to send data to the external Sink specified by ID.

        The Export Job will run asynchronously.
      responses:
        '200':
          description: Returns the export job data
          schema:
            $ref: '#/definitions/job'
  /api/sinkSchedules:
    get:
      summary: Get
      operationId: findSinkSchedules
      tags:
        - Sink Schedules
      description: |
        Returns a list of Sink Schedules
      responses:
        '200':
          description: Returns the matching sink schedules
          schema:
            type: array
            items:
              $ref: '#/definitions/exportSchedule'
    post:
      summary: Create
      operationId: createSinkSchedule
      tags:
        - Sink Schedules
      description: |
        Creates a new schedule associated with the given Sink.
      parameters:
        - name: exportSchedule
          in: body
          description: The sink schedule to add
          required: true
          schema:
            $ref: '#/definitions/exportSchedule'
      responses:
        '201':
          description: Returns the newly-added sink schedule
          schema:
            $ref: '#/definitions/exportSchedule'
  '/api/sinkSchedules/{exportScheduleId}':
    parameters:
      - $ref: '#/parameters/exportScheduleId'
    get:
      summary: Get
      operationId: findSinkScheduleById
      tags:
        - Sink Schedules
      description: |
        Get a Sink Schedule by the schedule's ID.
      responses:
        '200':
          description: Returns the sink schedule data
          schema:
            $ref: '#/definitions/exportSchedule'
    delete:
      summary: Delete
      operationId: deleteSinkScheduleById
      tags:
        - Sink Schedules
      description: |
        Deletes a single Sink Schedule based on the ID supplied
      responses:
        '200':
          description: Returns the sink schedule that was deleted
          schema:
            $ref: '#/definitions/exportSchedule'
  /api/sinkTypes:
    get:
      summary: List
      operationId: findSinksTypes
      tags:
        - Sink Types
      description: >
        Returns all Sink types.


        A Sink type describes a kind of Sink that can be created.

        For example a Sink type may describe the parameters available for
        writing to an external database such as Oracle or an external file
        system.


        A Sink can be created to write to a specific database or file system by
        filling out the configuration parameters listed by the Sink type and
        creating a Sink.
      responses:
        '200':
          description: Returns the matching sink types
          schema:
            type: array
            items:
              $ref: '#/definitions/sinkType'
  '/api/sinkTypes/{sinkTypeId}':
    parameters:
      - $ref: '#/parameters/sinkTypeId'
    get:
      summary: Get
      operationId: findSinkTypeById
      tags:
        - Sink Types
      responses:
        '200':
          description: Returns the sink type data
          schema:
            $ref: '#/definitions/sinkTypeDescription'
  '/api/exportJobs/{exportJobId}/shutdown':
    parameters:
      - $ref: '#/parameters/exportJobId'
    get:
      summary: Shutdown
      operationId: exportJobShutdownById
      tags:
        - Export Jobs
      description: |
        Shuts down a running export job.
      responses:
        '200':
          description: 200 OK
  /api/sourceInstances:
    post:
      summary: Create
      operationId: addSource
      tags:
        - Sources
      parameters:
        - name: sourceInstance
          in: body
          description: The source to add
          required: true
          schema:
            $ref: '#/definitions/sourceInstance'
      responses:
        '201':
          description: Returns the newly-added source
          schema:
            $ref: '#/definitions/sourceInstance'
          headers:
            Location:
              type: string
              description: The URL of the newly-added source
  '/api/sourceInstances/{sourceInstanceId}':
    parameters:
      - $ref: '#/parameters/sourceInstanceId'
    get:
      summary: Get
      operationId: findSourceById
      tags:
        - Sources
      responses:
        '200':
          description: Returns the source data
          schema:
            $ref: '#/definitions/source'
    delete:
      summary: Delete
      operationId: deleteSourceById
      tags:
        - Sources
      responses:
        '200':
          description: Returns the source that was deleted
          schema:
            $ref: '#/definitions/source'
    put:
      summary: Update
      operationId: updateSourceById
      tags:
        - Sources
      parameters:
        - name: sourceInstance
          in: body
          description: The source to update
          required: true
          schema:
            $ref: '#/definitions/sourceInstance'
      responses:
        '200':
          description: Returns the updated source data
          schema:
            $ref: '#/definitions/sourceInstance'
  /api/sourceTypeDescriptions:
    get:
      summary: List
      operationId: findSourceTypes
      tags:
        - Source Types
      description: >
        List the types of Sources available.


        Source types describe the parameters available for a specific type of
        Source such as an external database or file system from which data can
        be ingested into a Koverse Data Set.


        A Source that describes how to connect to a specific database or file
        system can be created by filling out the configuration parameters
        desribed by the Source type and submitting to /api/sourceInstances.
      responses:
        '200':
          description: Returns all source types with metadata
          schema:
            type: array
            items:
              $ref: '#/definitions/sourceTypeDescription'
  '/api/transformJobs/{transformJobId}/shutdown':
    parameters:
      - $ref: '#/parameters/transformJobId'
    get:
      summary: Shutdown
      operationId: shutdownTransformJobById
      tags:
        - Transform Jobs
      description: |
        Shutdown the Transform job specified by ID.
      responses:
        default:
          description: 200 OK
  /api/transforms:
    parameters:
      - name: inputDataSetId
        description: dataSet id to use when filtering transforms by inputs
        required: false
        type: string
        in: query
      - name: outputDataSetId
        description: dataSet id to use when filtering transforms by outputs
        required: false
        type: string
        in: query
    get:
      summary: List for a data set
      operationId: findTransforms
      tags:
        - Transforms
      description: >
        List Transforms associated with the specified Data Set.

        One of the query parameters must be specified, either a Data Set that is
        associated as the input to a Transform or the Data Set that is
        associated as the output of a Transform.
      responses:
        '200':
          description: Returns the matching transforms
          schema:
            type: array
            items:
              $ref: '#/definitions/transform'
    post:
      summary: Create
      operationId: addTransform
      tags:
        - Transforms
      parameters:
        - name: transform
          in: body
          description: The transform to add
          required: true
          schema:
            $ref: '#/definitions/transform'
      responses:
        '201':
          description: Returns the newly-added transform
          schema:
            $ref: '#/definitions/transform'
          headers:
            Location:
              type: string
              description: The URL of the newly-added transform
  '/api/transforms/{transformId}':
    parameters:
      - $ref: '#/parameters/transformId'
    get:
      summary: Get
      operationId: findTransformById
      tags:
        - Transforms
      description: |
        Get a Transform by the specified ID.
      responses:
        '200':
          description: Returns the transform data
          schema:
            $ref: '#/definitions/transform'
    delete:
      summary: Delete
      operationId: deleteTransformById
      tags:
        - Transforms
      responses:
        '200':
          description: Returns the transform that was deleted
          schema:
            $ref: '#/definitions/transform'
    put:
      summary: Update
      tags:
        - Transforms
      operationId: updateTransformById
      parameters:
        - name: transform
          in: body
          description: The updated transform info
          required: true
          schema:
            $ref: '#/definitions/transform'
      responses:
        '200':
          description: Returns the updated transform data
          schema:
            $ref: '#/definitions/transform'
  '/api/transforms/{transformId}/runTransform':
    parameters:
      - $ref: '#/parameters/transformId'
    get:
      summary: Start
      operationId: runTransform
      tags:
        - Transform Jobs
      description: >
        Starts a job to read data from the Transform's input data sets, apply
        the Transform's logic, and write output to the Transform's output Data
        Set.


        These jobs run asynchronously and are executed via the Spark or Hadoop
        MapReduce frameworks.
      responses:
        '200':
          description: Returns the success data
          schema:
            $ref: '#/definitions/success'
  '/api/transforms/{transformId}/transformSchedules':
    parameters:
      - $ref: '#/parameters/transformId'
    get:
      operationId: findTransformSchedules
      summary: List
      tags:
        - Transform Schedules
      description: |
        List Transform Schedules associated with the given Transform ID.
      responses:
        '200':
          description: Returns the matching transform schedules
          schema:
            type: array
            items:
              $ref: '#/definitions/transformSchedule'
    post:
      summary: Create
      operationId: addTransformSchedule
      tags:
        - Transform Schedules
      description: |
        Create Transform Schedule.
      parameters:
        - name: transformSchedule
          in: body
          description: The transform schedule to add
          required: true
          schema:
            $ref: '#/definitions/transformSchedule'
      responses:
        '201':
          description: Returns the newly-added transform schedule
          schema:
            $ref: '#/definitions/transformSchedule'
  '/api/transforms/{transformId}/transformSchedules/{transformScheduleId}':
    parameters:
      - $ref: '#/parameters/transformId'
      - $ref: '#/parameters/transformScheduleId'
    delete:
      summary: Delete
      operationId: deleteTransformScheduleById
      tags:
        - Transform Schedules
      responses:
        '200':
          description: Returns the transform schedule that was deleted
          schema:
            $ref: '#/definitions/transformSchedule'
  /api/transformTypes:
    get:
      summary: List
      operationId: findTransformTypes
      tags:
        - Transform Types
      description: >
        Get a list of descriptions of a specific Transform types that include
        the available configuration parameters.


        This information is used to help create a new Transform that has its
        configuration parameters filled out properly.
      responses:
        '200':
          description: Returns a list of transform types
          schema:
            type: array
            items:
              $ref: '#/definitions/transformType'
  '/api/transformTypes/{typeId}':
    parameters:
      - name: typeId
        type: string
        in: path
        description: The transform type id
        required: true
    get:
      summary: Get
      operationId: findDataSetTransformById
      tags:
        - Transform Types
      description: >
        Get a description of a specific Transform type that includes the
        available configuration parameters.


        This information is used to help create a new Transform that has its
        configuration parameters filled out properly.

        For example, a Sentiment Analysis Transform may have a type that
        describes a parameter that requires the name of a field containing text
        to be analyzed.
      responses:
        '200':
          description: Returns the transform type
          schema:
            $ref: '#/definitions/transformType'
  /api/query/:
    get:
      summary: Lucene style
      operationId: queryLucene
      tags:
        - Query
      description: >
        This method is useful for apps that want to allow users to create

        their own queries using Lucene syntax. Queries can be issued for one

        or more data sets simultaneously via the dataSets parameter.


        ### Lucene Query Syntax


        #### Overview


        Koverse supports the most important subset of Lucene query features.

        The syntax allows for rich querying by using Boolean logic, term
        grouping, ranges, and wildcard matching.

        This section will explain the extent of Lucene syntax support and call
        out the small amount of unsupported features.



        #### Terms


        Terms are what values to search for in the records.

        They can be specified as either a string of text or a number.

        When searching for a single word, it is not necessary to use quotes.

        When searching for a phrase, quotes can be used, such "yellow
        submarine".


        It is not necessary to specify which field(s) to search under.

        The default is to search all fields.


        To search for a term, simply use it, like: ``cat`` or ``123``.

        Phrases just need double quotes, such as: ``"cat food"``.


        Terms that in the ISO 8601 format will be interpreted as dates.

        This is an international format that takes the form of
        ``2018-10-30T12:48:29Z``.

        A complete description of this format can be found at

        https://en.wikipedia.org/wiki/ISO_8601.


        Terms that in the form of a number, such as ``123`` or ``123.123`` will
        be interpreted as numbers.


        Terms can also be interpreted as Internet Protocol address, such as
        ``127.0.0.1``.



        #### Fields


        It is possible to limit what fields to search within.

        To do so, simply specify the field name followed by a color, such as:

        ``animal:cat``, ``size:123``, or ``eats:"cat food"``.



        #### Wildcards


        Wild cards are supported for string terms, but only at the end of the
        term.

        For example: ``animal:cat*``.

        Wildcards are not supported in the beginning or middle of a term,

        which is different than what Lucene normally supports.



        #### Ranges


        It is possible to search within a range of terms.

        Simply surround the two terms with square brackets,

        separated by ``TO``.

        For example, ``size:[2 TO 10]`` will search for all sizes with a number

        from 2 to 10, inclusive.

        Exclusive searches can be specified by using curly braces,

        such as: ``size:{1 TO 11}``.

        Additionally, it is possible to perform an inclusive search on text
        terms,

        such as: ``name:[chad TO sigrid]``.



        #### Boolean Operators


        The following operators are supported: ``AND``, ``OR``, and ``NOT``.

        The default operator is ``OR``.

        For example, the query ``chad sigrid`` is equivalent to ``chad OR
        sigrid``.

        An example ``AND`` query would be: ``animal:cat AND owner:sigrid``.

        An example ``NOT`` query is: ``NOT animal:cat`` or ``NOT size:12``.


        ``AND``, ``OR``, and ``NOT`` can also be specified using

        ``&&``, ``||``, and ``!``, respectively.



        #### Grouping


        A search be be logically grouped by using parenthesis.

        For example, the queries

        ``(animal:cat OR animal:dog) AND owner:chad``

        and

        ``animal:cat OR (animal:dog AND owner:chad)``

        are not the same.

        The first query searches all cats and dogs owned by chad.

        The second query searches for all cats, or all dogs owned by chad.



        #### Escaping Special Characters


        Characters that are search keywords such as ``:``, ``(``, and ``)`` can
        be

        escaped with a forward slash.

        For example, to search for a term that includes a parenthesis,

        the parenthesis can be escaped with ``\``:

        ``animal:\(four legs\)``.

        Here are all of the reserved search keywords:

        ``+ - && || ! ( ) { } [ ] ^ " ~ * ? : \``.



        #### Unsupported Lucene Features


        Relevance ranking: Matching records that are returned from Koverse are
        not sorted in any particular order.


        However, when paging is used, the results are returned in a consistent
        order.

        For example, when requesting a page multiple times, the same results are
        returned.

        Thus, it is possible to show the user the first page of results and
        allow them to then navigate to other pages.

        When doing so, the user will see the same records for each page every
        time they request them.

        What is not possible is to sort those results globally.

        However, a page's worth of records could be sorted by the client
        program.



        #### Unsupported Lucene Syntax


        The full Lucene syntax can be read online at

        https://lucene.apache.org/core/2_9_4/queryparsersyntax.html .


        However, note that the following features are not supported in Koverse:

         * Any wildcard searches other than suffix-based.
         * Single character wildcard searches.
         * Fuzzy searches.
         * Proximity searches.
         * Term boosting.
         * The "required" operator ``+``.
         * Field grouping.
      parameters:
        - in: query
          name: query
          type: string
          required: true
          description: >
            Lucene syntax query string. See above description for details on
            syntax.
        - in: query
          name: dataSets
          type: string
          required: true
          description: >
            A comma separated list of dataSetIds. Specifying a blank string will
            cause the query to be issued to all data sets the user is allowed to
            query.
        - in: query
          name: auths
          type: string
          required: false
          description: >
            An optional comma separated list of authorization tokens. These are
            used for applying record-level filtering of data set results to
            records that have additional security labels applied.
        - in: query
          name: numRecords
          type: integer
          format: int32
          required: false
          description: |
            The number of records to include in the response.
        - in: query
          name: recordOffset
          type: integer
          format: int64
          required: false
          description: >
            The number of records in the query response to skip. This is used to
            implement paging in applications.
        - in: query
          name: fieldsToReturn
          type: string
          required: false
          description: >
            A comma separated list of field names which can be used to restrict
            the fields included in the response records returned.
      responses:
        '200':
          description: Query results
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetResult'
  /api/query/object:
    post:
      summary: Object style with IDs
      operationId: queryObject
      tags:
        - Query
      description: >
        Query using a JSON document and data set IDs.


        ### Object Search Syntax


        For searches that are not written by end-users on the fly but that are
        constructed programmatically by a web application, we recommend using
        Koverse's Object Search Syntax.

        The Object Search Syntax allows applications to specify search criteria
        by building a Javascript object, converting to JSON, and submitting to a
        REST endpoint.

        This way, a search can be more easily manipulated programmatically by
        Javascript.


        The following table shows the JSON syntax for various types of searches:



        |Search Criteria                    | Query
        Syntax                                  |

        |-----------------------------------|-----------------------------------------------|

        | Searching 'any' field for a value | {"$any":
        "fmv"}                               |

        | Search specific field for a value | {"field.name":
        "fmv"}                         |

        | Search AND                        | {"$and": [{"$any": "fmv"},
        {"$any": "blue"}]} |

        | Search OR                         | {"$or": [{"$any": "fmv"}, {"$any":
        "blue"}]}  |


        These searches allow various criteria to be combined using operators
        like AND and OR.

        Note that the terms of these search are all 'point' terms, meaning they
        specific an exact value.

        Searching for a range of values is also supported.


        #### Searching Ranges


        To search for a range of values, use one of the range operators such as
        $gte, greater than or equals, etc.

        A few types of ranges are listed in the following table:


        |Search Criteria                         | Query
        Syntax                                                    |

        |----------------------------------------|-----------------------------------------------------------------|

        | Any value greater than or equal to 160 | { "$any": { "$gte": 160
        }}                                      |

        | Date field less than a specific date   | { "date_created": { "$lt":
        "1980-01-01T00:00:00.000Z }}         |

        | Geo Range                              | { "fieldName": { "$box":
        [[sw-lat, sw-long],[ne-lat, ne-long]]}}|

        |                                        | { "fieldName": { "$box"
        :[[39.5, -104.9],[40, -104.5]] }}       |

        |Any value except for 100                | { "$not": { "amount": 100 }
        }                                   |



        The official list of operators includes:


        - $gt greater than

        - $gte greater than or equal to

        - $lt less than

        - $lte less than or equal to

        - $eq equal to

        - $any used in place of a field to search for a value in any field

        - $not used to negate a search criterion. Note that this results in two
        ranges being searched, those 'above' and 'below' the value specified.


        Note that queries that combine a range with any other criteria, and
        queries that combine multiple ranges require Composite Indexes on the
        fields involved.
      parameters:
        - $ref: '#/parameters/objectQuery'
      responses:
        '200':
          description: Query results
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetResult'
  /api/query/object/names:
    post:
      summary: Object style with names
      operationId: queryObjectNames
      tags:
        - Query
      description: >
        Query using a JSON document and data set names.


        ### Object Search Syntax


        For searches that are not written by end-users on the fly but that are
        constructed programmatically by a web application, we recommend using
        Koverse's Object Search Syntax.

        The Object Search Syntax allows applications to specify search criteria
        by building a Javascript object, converting to JSON, and submitting to a
        REST endpoint.

        This way, a search can be more easily manipulated programmatically by
        Javascript.


        The following table shows the JSON syntax for various types of searches:



        |Search Criteria                    | Query
        Syntax                                  |

        |-----------------------------------|-----------------------------------------------|

        | Searching 'any' field for a value | {"$any":
        "fmv"}                               |

        | Search specific field for a value | {"field.name":
        "fmv"}                         |

        | Search AND                        | {"$and": [{"$any": "fmv"},
        {"$any": "blue"}]} |

        | Search OR                         | {"$or": [{"$any": "fmv"}, {"$any":
        "blue"}]}  |


        These searches allow various criteria to be combined using operators
        like AND and OR.

        Note that the terms of these search are all 'point' terms, meaning they
        specific an exact value.

        Searching for a range of values is also supported.


        #### Searching Ranges


        To search for a range of values, use one of the range operators such as
        $gte, greater than or equals, etc.

        A few types of ranges are listed in the following table:


        |Search Criteria                         | Query
        Syntax                                                    |

        |----------------------------------------|-----------------------------------------------------------------|

        | Any value greater than or equal to 160 | { "$any": { "$gte": 160
        }}                                      |

        | Date field less than a specific date   | { "date_created": { "$lt":
        "1980-01-01T00:00:00.000Z }}         |

        | Geo Range                              | { "fieldName": { "$box":
        [[sw-lat, sw-long],[ne-lat, ne-long]]}}|

        |                                        | { "fieldName": { "$box"
        :[[39.5, -104.9],[40, -104.5]] }}       |

        |Any value except for 100                | { "$not": { "amount": 100 }
        }                                   |



        The official list of operators includes:


        - $gt greater than

        - $gte greater than or equal to

        - $lt less than

        - $lte less than or equal to

        - $eq equal to

        - $any used in place of a field to search for a value in any field

        - $not used to negate a search criterion. Note that this results in two
        ranges being searched, those 'above' and 'below' the value specified.


        Note that queries that combine a range with any other criteria, and
        queries that combine multiple ranges require Composite Indexes on the
        fields involved.
      parameters:
        - $ref: '#/parameters/objectQueryNames'
      responses:
        '200':
          description: Query results
          schema:
            type: array
            items:
              $ref: '#/definitions/dataSetResult'
